Topics Discussed:
Docker Introduction: Session 51 

Vitualization --> Logical isolation of one pysical systems into multiple systems

Image is Static and immutable 
Container is Dynamic it can be runnable and mutable 

docker pull 
docker create 
docker start

docker run = pull + Create + Start

docker port forwarding

Docker FROM
Docker RUN
Docker CMD
Docker EntryPoint

Labels Instruction: Session 52:

    LABEL : Giving key value pairs to the docker file
    lables are the key-value pairs that represents the tags for images not for the containers
    images can be filtered based on the labels like 
    docker build -t <image-name> .
    docker images --filter labels=key=value
    docker inspect <image-id> --> This can inspect all the details about the images

Expose Instruction :
    we can instruct the container builder to set the port for the conatiner based on the expose instruction 
    EXPOSE 80/tcp
    expose will not adding any functionalities this is just instruction for conatiner builder

ENV Instruction :
    we can add environment variables to the container 
    it is as same as Labels but env will be used in conatiner but lables will not 

Docker Copy:
    Copy The content from local to Image/conatiner

Docker ADD :
    This command will copy the content from local to image/container
    This also copy the content from internet 
    This also copy the content by unzipping automatically 

Docker CMD:
    CMD ["executable","param1","param2"]
 
Docker Session -- 53 

Docker USER Instructions: Instructions
Docker WorkDirectory: Instead of cd command in normal linux we used workdir instruction to set the workdirectory where we should save the file 

Docker Arg Commands:
    it will supply the variables at the build time but not supply at container run time 
    to supply arguments at run time we need to use it like 
    env var1=arg1

Docker OnBuild :
    On Build will work at container run time not at image build time

Docker Is Easy Portable 
AMI --> Heavy Size ,Full Operating System ,Mutable, Immovable,
docker-compose up -d 
docker-compose down -d

Volumes : Docker Volumes
    Docker is Ephemeral In nature
    Databases --> RDBMS,NoSQL,Redis,MQ,MySQL
1) Docker Named Volumes
2) Docker UnNamed Volumes

Volumes:
    -v <host-path>:<container-path>
Docker is storing temporary volumes in the directory -->/var/lib/docker/overlay2 --> temporary volumes

UnNamed Volumes:(Bind Mounting/Bind Volume)
    Create a Directory and map it with the docker containers data store
    We have to manage the directory
    docker run -it -v <host_path>:<container_path> <image_name> /bin/bash

Named Volumes:
    Docker Should manage these volumes
    Everything is managed by docker commands
    docker run -it -v <volume_name>:/data <image_name> /bin/bash

docker inspect <container-id> --.
docker volume inspect <container-id>
docker volumes ls --> list down all the vloumes

StateFul Applications:
    Mongodb
    MySQL
    Reddis
    RabbitMQ
docker run -p <host-port>:<container-port> -v <host volume path>:<conatiner-volume-path> --name <container name> 

Docker Compose File:
*****
volumes:
- source: rabbitmq
  target: /var/lib/rabbitmq
  type: volume
*****


Docker Best Practices:

1) Creating Named Volumes is Best Practices
2) Create Networking is best Practices
3) Use Official Images
4) Try To reduce the memory using multistage building etc..
5) By Using Office Alpine images memory will be reduces to almost 100 perecnt
6) MultiStage Builds Mention 
7) Use Distroless Images
8) Use Docker Security Scanning

Docker Session - 56

Docker Architecture:
    Docker CLI --> Where we write Docker Commands
    Docker Daemon --> Where all The containers are managed using daemon
    Docker HUB --> Where Docker Images are build and pushed for public use

Docker Layers:
    Once we create the image we cannot change image
    docker image is immutable and static in nature

    Each Instruction in the Docker file is Called the Docker layer.

    Each instruction will create one image and one mini container will create.

    There is one component will be there to run and build everything that is docker engine

    One layer will create one image and one container on top of each container the next instructions will be run when the instruction moves to next then previous mini container created by Docker Engine will be destroyed.

Docker Disadvantages:
    1) What will Happen if Docker Server is Down
    2) What happens if you suddenly get more traffic
    3) How to balance the load if you have multiple containers
    4) Self Healing --> what happens when the correct resources arent reached
    5) what about Secrets and Configs --> SSM Parameters are Stored

Container Orchestration:
    Orchestra Means --> Where one Person can manages the different persons to get the work done

    One Person Giving the Instrctions to another persons 

    When containers are running we need to manage those containers 
    
    Docker Run --> Creating Container Out Of Image
    Image --> Physical File Static,Immutable, Builder File

Kubernetes: For Better Networking,Storage Solutions and Security instead of Docker Swarm.




 








    